{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "from datetime import datetime, timedelta\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_dates = pd.read_csv('data/DST_fri_mon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_fri_dates = list(dst_dates['fall_fri_before'])+list(dst_dates['spring_fri_before'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(stock):\n",
    "    # drop null (for Yahoo, it seems that it's 'high' that is null)\n",
    "    stock = stock.dropna(subset=['High'])\n",
    "    # reverses the dataframe; Yahoo is from more recent to latest; I wanted to reverse the chronology\n",
    "    stock = stock.iloc[::-1].reset_index(drop=True)\n",
    "\n",
    "    # Exclude the 'Date' column and convert the rest to numeric\n",
    "    stock.loc[:, stock.columns != 'Date'] = stock.loc[:, stock.columns != 'Date'].applymap(\n",
    "        lambda x: pd.to_numeric(str(x).replace(',', ''), errors='coerce')\n",
    "    )\n",
    "\n",
    "    stock['datetime'] = pd.to_datetime(stock['Date'], errors='coerce')\n",
    "\n",
    "    # Filter for Fridays and Mondays\n",
    "    filtered_stock= stock[stock['datetime'].dt.dayofweek.isin([0, 4])]\n",
    "\n",
    "    # Create a new column 'DayType' indicating 'Monday' or 'Friday'\n",
    "    filtered_stock['DayType'] = np.where(filtered_stock['datetime'].dt.dayofweek == 0, 'Monday', 'Friday')\n",
    "\n",
    "    stock=filtered_stock\n",
    "    \n",
    "    # Initialize a list to store the valid rows\n",
    "    valid_rows = []\n",
    "\n",
    "    # Iterate through the group (stock data) to check Friday-Monday intervals\n",
    "    for i in range(len(stock) - 1):\n",
    "        current_day = stock.iloc[i]['DayType']\n",
    "        next_day = stock.iloc[i + 1]['DayType']\n",
    "        current_date = stock.iloc[i]['datetime']\n",
    "        next_date = stock.iloc[i + 1]['datetime']\n",
    "\n",
    "        # Check if current day is Friday and next day is Monday\n",
    "        if current_day == 'Friday' and next_day == 'Monday':\n",
    "            # Calculate the difference in days\n",
    "            days_diff = (next_date - current_date).days\n",
    "            # If the difference is within 3 days, add both rows to the valid list\n",
    "            if days_diff <= 3:\n",
    "                valid_rows.append(stock.iloc[i])       # Add the Friday row\n",
    "                valid_rows.append(stock.iloc[i + 1])   # Add the Monday row\n",
    "\n",
    "    # Create a new DataFrame from the valid rows\n",
    "    valid_pairs_df = pd.DataFrame(valid_rows).reset_index(drop=True)\n",
    "    \n",
    "    # Initialize a list to store the combined rows\n",
    "    combined_rows = []\n",
    "\n",
    "    # Iterate through the valid pairs (step by 2 because each pair has a Friday and a Monday)\n",
    "    for i in range(0, len(valid_pairs_df), 2):\n",
    "        # Get the Friday and Monday rows\n",
    "        friday_row = valid_pairs_df.iloc[i]\n",
    "        monday_row = valid_pairs_df.iloc[i + 1]\n",
    "\n",
    "        # Combine the data into a single row (prefix columns with 'Friday_' and 'Monday_')\n",
    "        combined_data = {\n",
    "            'Friday_date': friday_row['datetime'],     # Friday date\n",
    "            'Monday_date': monday_row['datetime'],     # Monday date\n",
    "            'Friday_day': friday_row['DayType'],       # Should be 'Friday'\n",
    "            'Monday_day': monday_row['DayType'],       # Should be 'Monday'\n",
    "        }\n",
    "\n",
    "        # Add all other columns, prefixing them with 'Friday_' or 'Monday_'\n",
    "        for col in friday_row.index:\n",
    "            if col not in ['datetime', 'DayType']:\n",
    "                combined_data[f'Friday_{col}'] = friday_row[col]\n",
    "                combined_data[f'Monday_{col}'] = monday_row[col]\n",
    "\n",
    "        # Append the combined data to the list\n",
    "        combined_rows.append(combined_data)\n",
    "\n",
    "    # Create a new DataFrame from the combined rows\n",
    "    combined_df = pd.DataFrame(combined_rows)\n",
    "\n",
    "    combined_df.drop(columns=['Friday_day', 'Monday_day'], inplace=True)\n",
    "\n",
    "    combined_df.drop(columns=['Friday_Date', 'Monday_Date'], inplace=True)\n",
    "\n",
    "    stock = combined_df\n",
    "    stock['y'] = stock['Friday_date'].isin(dst_fri_dates).astype(int)\n",
    "\n",
    "    return stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIB: Bancolombia S.A., Finance (commercial banks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIB = pd.read_csv('data/CIB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26-Nov-24</td>\n",
       "      <td>33.11</td>\n",
       "      <td>33.06</td>\n",
       "      <td>32.69</td>\n",
       "      <td>32.87</td>\n",
       "      <td>32.87</td>\n",
       "      <td>93,609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-Nov-24</td>\n",
       "      <td>33.01</td>\n",
       "      <td>33.63</td>\n",
       "      <td>32.84</td>\n",
       "      <td>33.33</td>\n",
       "      <td>33.33</td>\n",
       "      <td>507,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22-Nov-24</td>\n",
       "      <td>32.8</td>\n",
       "      <td>32.99</td>\n",
       "      <td>32.61</td>\n",
       "      <td>32.79</td>\n",
       "      <td>32.79</td>\n",
       "      <td>85,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21-Nov-24</td>\n",
       "      <td>33.3</td>\n",
       "      <td>33.61</td>\n",
       "      <td>32.76</td>\n",
       "      <td>32.76</td>\n",
       "      <td>32.76</td>\n",
       "      <td>184,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20-Nov-24</td>\n",
       "      <td>32.86</td>\n",
       "      <td>33.50</td>\n",
       "      <td>32.76</td>\n",
       "      <td>33.47</td>\n",
       "      <td>33.47</td>\n",
       "      <td>375,800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date   Open   High    Low  Close   Adj Close    Volume\n",
       "0  26-Nov-24  33.11  33.06  32.69   32.87       32.87   93,609\n",
       "1  25-Nov-24  33.01  33.63  32.84   33.33       33.33  507,800\n",
       "2  22-Nov-24   32.8  32.99  32.61   32.79       32.79   85,300\n",
       "3  21-Nov-24   33.3  33.61  32.76   32.76       32.76  184,400\n",
       "4  20-Nov-24  32.86  33.50  32.76   33.47       33.47  375,800"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CIB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stock.loc[:, stock.columns != 'Date'] = stock.loc[:, stock.columns != 'Date'].applymap(\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  stock['datetime'] = pd.to_datetime(stock['Date'], errors='coerce')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_stock['DayType'] = np.where(filtered_stock['datetime'].dt.dayofweek == 0, 'Monday', 'Friday')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:76: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  stock['y'] = stock['Friday_date'].isin(dst_fri_dates).astype(int)\n"
     ]
    }
   ],
   "source": [
    "CIB=cleaner(CIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIB.to_csv('data/CIB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Friday_date</th>\n",
       "      <th>Monday_date</th>\n",
       "      <th>Friday_Open</th>\n",
       "      <th>Monday_Open</th>\n",
       "      <th>Friday_High</th>\n",
       "      <th>Monday_High</th>\n",
       "      <th>Friday_Low</th>\n",
       "      <th>Monday_Low</th>\n",
       "      <th>Friday_Close</th>\n",
       "      <th>Monday_Close</th>\n",
       "      <th>Friday_Adj Close</th>\n",
       "      <th>Monday_Adj Close</th>\n",
       "      <th>Friday_Volume</th>\n",
       "      <th>Monday_Volume</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>39.49</td>\n",
       "      <td>40.74</td>\n",
       "      <td>40.88</td>\n",
       "      <td>41.32</td>\n",
       "      <td>39.49</td>\n",
       "      <td>40.50</td>\n",
       "      <td>40.78</td>\n",
       "      <td>40.69</td>\n",
       "      <td>28.21</td>\n",
       "      <td>28.15</td>\n",
       "      <td>195200</td>\n",
       "      <td>173500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>43.02</td>\n",
       "      <td>43.00</td>\n",
       "      <td>43.50</td>\n",
       "      <td>43.66</td>\n",
       "      <td>42.77</td>\n",
       "      <td>42.82</td>\n",
       "      <td>43.48</td>\n",
       "      <td>43.60</td>\n",
       "      <td>30.08</td>\n",
       "      <td>30.16</td>\n",
       "      <td>401800</td>\n",
       "      <td>169500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>43.87</td>\n",
       "      <td>43.11</td>\n",
       "      <td>44.00</td>\n",
       "      <td>43.58</td>\n",
       "      <td>43.24</td>\n",
       "      <td>43.01</td>\n",
       "      <td>43.58</td>\n",
       "      <td>43.35</td>\n",
       "      <td>30.14</td>\n",
       "      <td>29.99</td>\n",
       "      <td>257100</td>\n",
       "      <td>348200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>44.41</td>\n",
       "      <td>44.61</td>\n",
       "      <td>45.08</td>\n",
       "      <td>46.54</td>\n",
       "      <td>44.30</td>\n",
       "      <td>44.61</td>\n",
       "      <td>45.00</td>\n",
       "      <td>46.50</td>\n",
       "      <td>31.13</td>\n",
       "      <td>32.16</td>\n",
       "      <td>267900</td>\n",
       "      <td>281900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>46.40</td>\n",
       "      <td>46.00</td>\n",
       "      <td>46.56</td>\n",
       "      <td>46.03</td>\n",
       "      <td>45.76</td>\n",
       "      <td>45.54</td>\n",
       "      <td>46.16</td>\n",
       "      <td>45.56</td>\n",
       "      <td>31.93</td>\n",
       "      <td>31.51</td>\n",
       "      <td>129900</td>\n",
       "      <td>136500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Friday_date Monday_date  Friday_Open  Monday_Open  Friday_High  Monday_High  \\\n",
       "0  2019-01-04  2019-01-07        39.49        40.74        40.88        41.32   \n",
       "1  2019-01-11  2019-01-14        43.02        43.00        43.50        43.66   \n",
       "2  2019-01-25  2019-01-28        43.87        43.11        44.00        43.58   \n",
       "3  2019-02-01  2019-02-04        44.41        44.61        45.08        46.54   \n",
       "4  2019-02-08  2019-02-11        46.40        46.00        46.56        46.03   \n",
       "\n",
       "   Friday_Low  Monday_Low  Friday_Close   Monday_Close   Friday_Adj Close   \\\n",
       "0       39.49       40.50          40.78          40.69              28.21   \n",
       "1       42.77       42.82          43.48          43.60              30.08   \n",
       "2       43.24       43.01          43.58          43.35              30.14   \n",
       "3       44.30       44.61          45.00          46.50              31.13   \n",
       "4       45.76       45.54          46.16          45.56              31.93   \n",
       "\n",
       "   Monday_Adj Close   Friday_Volume  Monday_Volume  y  \n",
       "0              28.15         195200         173500  0  \n",
       "1              30.16         401800         169500  0  \n",
       "2              29.99         257100         348200  0  \n",
       "3              32.16         267900         281900  0  \n",
       "4              31.51         129900         136500  0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CIB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P500 ^GSPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500=pd.read_csv('data/SP500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stock.loc[:, stock.columns != 'Date'] = stock.loc[:, stock.columns != 'Date'].applymap(\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  stock['datetime'] = pd.to_datetime(stock['Date'], errors='coerce')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_stock['DayType'] = np.where(filtered_stock['datetime'].dt.dayofweek == 0, 'Monday', 'Friday')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:76: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  stock['y'] = stock['Friday_date'].isin(dst_fri_dates).astype(int)\n"
     ]
    }
   ],
   "source": [
    "sp500=cleaner(sp500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Friday_date</th>\n",
       "      <th>Monday_date</th>\n",
       "      <th>Friday_Open</th>\n",
       "      <th>Monday_Open</th>\n",
       "      <th>Friday_High</th>\n",
       "      <th>Monday_High</th>\n",
       "      <th>Friday_Low</th>\n",
       "      <th>Monday_Low</th>\n",
       "      <th>Friday_Close</th>\n",
       "      <th>Monday_Close</th>\n",
       "      <th>Friday_Adj Close</th>\n",
       "      <th>Monday_Adj Close</th>\n",
       "      <th>Friday_Volume</th>\n",
       "      <th>Monday_Volume</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>2474.33</td>\n",
       "      <td>2535.61</td>\n",
       "      <td>2538.07</td>\n",
       "      <td>2566.16</td>\n",
       "      <td>2474.33</td>\n",
       "      <td>2524.56</td>\n",
       "      <td>2531.94</td>\n",
       "      <td>2549.69</td>\n",
       "      <td>2531.94</td>\n",
       "      <td>2549.69</td>\n",
       "      <td>4234140000</td>\n",
       "      <td>4133120000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>2588.11</td>\n",
       "      <td>2580.31</td>\n",
       "      <td>2596.27</td>\n",
       "      <td>2589.32</td>\n",
       "      <td>2577.40</td>\n",
       "      <td>2570.41</td>\n",
       "      <td>2596.26</td>\n",
       "      <td>2582.61</td>\n",
       "      <td>2596.26</td>\n",
       "      <td>2582.61</td>\n",
       "      <td>3447460000</td>\n",
       "      <td>3689370000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>2657.44</td>\n",
       "      <td>2644.97</td>\n",
       "      <td>2672.38</td>\n",
       "      <td>2644.97</td>\n",
       "      <td>2657.33</td>\n",
       "      <td>2624.06</td>\n",
       "      <td>2664.76</td>\n",
       "      <td>2643.85</td>\n",
       "      <td>2664.76</td>\n",
       "      <td>2643.85</td>\n",
       "      <td>3821000000</td>\n",
       "      <td>3630820000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>2702.32</td>\n",
       "      <td>2706.49</td>\n",
       "      <td>2716.66</td>\n",
       "      <td>2724.99</td>\n",
       "      <td>2696.88</td>\n",
       "      <td>2698.75</td>\n",
       "      <td>2706.53</td>\n",
       "      <td>2724.87</td>\n",
       "      <td>2706.53</td>\n",
       "      <td>2724.87</td>\n",
       "      <td>3782490000</td>\n",
       "      <td>3369450000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>2692.36</td>\n",
       "      <td>2712.40</td>\n",
       "      <td>2708.07</td>\n",
       "      <td>2718.05</td>\n",
       "      <td>2681.83</td>\n",
       "      <td>2703.79</td>\n",
       "      <td>2707.88</td>\n",
       "      <td>2709.80</td>\n",
       "      <td>2707.88</td>\n",
       "      <td>2709.80</td>\n",
       "      <td>3649510000</td>\n",
       "      <td>3395330000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Friday_date Monday_date  Friday_Open  Monday_Open  Friday_High  Monday_High  \\\n",
       "0  2019-01-04  2019-01-07      2474.33      2535.61      2538.07      2566.16   \n",
       "1  2019-01-11  2019-01-14      2588.11      2580.31      2596.27      2589.32   \n",
       "2  2019-01-25  2019-01-28      2657.44      2644.97      2672.38      2644.97   \n",
       "3  2019-02-01  2019-02-04      2702.32      2706.49      2716.66      2724.99   \n",
       "4  2019-02-08  2019-02-11      2692.36      2712.40      2708.07      2718.05   \n",
       "\n",
       "   Friday_Low  Monday_Low  Friday_Close   Monday_Close   Friday_Adj Close   \\\n",
       "0     2474.33     2524.56        2531.94        2549.69            2531.94   \n",
       "1     2577.40     2570.41        2596.26        2582.61            2596.26   \n",
       "2     2657.33     2624.06        2664.76        2643.85            2664.76   \n",
       "3     2696.88     2698.75        2706.53        2724.87            2706.53   \n",
       "4     2681.83     2703.79        2707.88        2709.80            2707.88   \n",
       "\n",
       "   Monday_Adj Close   Friday_Volume  Monday_Volume  y  \n",
       "0            2549.69     4234140000     4133120000  0  \n",
       "1            2582.61     3447460000     3689370000  0  \n",
       "2            2643.85     3821000000     3630820000  0  \n",
       "3            2724.87     3782490000     3369450000  0  \n",
       "4            2709.80     3649510000     3395330000  0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.to_csv('data/sp500.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AHH: Armada Hoffler Properties, Inc., Finance (real estate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "AHH=pd.read_csv('data/AHH.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "AHH = AHH.iloc[::-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stock.loc[:, stock.columns != 'Date'] = stock.loc[:, stock.columns != 'Date'].applymap(\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  stock['datetime'] = pd.to_datetime(stock['Date'], errors='coerce')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_stock['DayType'] = np.where(filtered_stock['datetime'].dt.dayofweek == 0, 'Monday', 'Friday')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:76: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  stock['y'] = stock['Friday_date'].isin(dst_fri_dates).astype(int)\n"
     ]
    }
   ],
   "source": [
    "AHH=cleaner(AHH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Friday_date</th>\n",
       "      <th>Monday_date</th>\n",
       "      <th>Friday_Open</th>\n",
       "      <th>Monday_Open</th>\n",
       "      <th>Friday_High</th>\n",
       "      <th>Monday_High</th>\n",
       "      <th>Friday_Low</th>\n",
       "      <th>Monday_Low</th>\n",
       "      <th>Friday_Close</th>\n",
       "      <th>Monday_Close</th>\n",
       "      <th>Friday_Adj Close</th>\n",
       "      <th>Monday_Adj Close</th>\n",
       "      <th>Friday_Volume</th>\n",
       "      <th>Monday_Volume</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>13.84</td>\n",
       "      <td>14.22</td>\n",
       "      <td>14.15</td>\n",
       "      <td>14.39</td>\n",
       "      <td>13.71</td>\n",
       "      <td>14.02</td>\n",
       "      <td>14.07</td>\n",
       "      <td>14.30</td>\n",
       "      <td>10.17</td>\n",
       "      <td>10.34</td>\n",
       "      <td>202700</td>\n",
       "      <td>306200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-11</td>\n",
       "      <td>2019-01-14</td>\n",
       "      <td>14.79</td>\n",
       "      <td>14.73</td>\n",
       "      <td>14.85</td>\n",
       "      <td>14.95</td>\n",
       "      <td>14.64</td>\n",
       "      <td>14.58</td>\n",
       "      <td>14.81</td>\n",
       "      <td>14.62</td>\n",
       "      <td>10.70</td>\n",
       "      <td>10.57</td>\n",
       "      <td>201000</td>\n",
       "      <td>361700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>2019-01-28</td>\n",
       "      <td>14.43</td>\n",
       "      <td>14.42</td>\n",
       "      <td>14.60</td>\n",
       "      <td>14.70</td>\n",
       "      <td>14.41</td>\n",
       "      <td>14.38</td>\n",
       "      <td>14.51</td>\n",
       "      <td>14.62</td>\n",
       "      <td>10.49</td>\n",
       "      <td>10.57</td>\n",
       "      <td>185900</td>\n",
       "      <td>229200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>15.03</td>\n",
       "      <td>14.97</td>\n",
       "      <td>15.10</td>\n",
       "      <td>15.30</td>\n",
       "      <td>14.76</td>\n",
       "      <td>14.93</td>\n",
       "      <td>14.99</td>\n",
       "      <td>15.30</td>\n",
       "      <td>10.83</td>\n",
       "      <td>11.06</td>\n",
       "      <td>119500</td>\n",
       "      <td>148000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>2019-02-11</td>\n",
       "      <td>15.08</td>\n",
       "      <td>15.02</td>\n",
       "      <td>15.36</td>\n",
       "      <td>15.45</td>\n",
       "      <td>15.08</td>\n",
       "      <td>15.02</td>\n",
       "      <td>15.19</td>\n",
       "      <td>15.43</td>\n",
       "      <td>10.98</td>\n",
       "      <td>11.15</td>\n",
       "      <td>194300</td>\n",
       "      <td>239400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Friday_date Monday_date  Friday_Open  Monday_Open  Friday_High  Monday_High  \\\n",
       "0  2019-01-04  2019-01-07        13.84        14.22        14.15        14.39   \n",
       "1  2019-01-11  2019-01-14        14.79        14.73        14.85        14.95   \n",
       "2  2019-01-25  2019-01-28        14.43        14.42        14.60        14.70   \n",
       "3  2019-02-01  2019-02-04        15.03        14.97        15.10        15.30   \n",
       "4  2019-02-08  2019-02-11        15.08        15.02        15.36        15.45   \n",
       "\n",
       "   Friday_Low  Monday_Low  Friday_Close   Monday_Close   Friday_Adj Close   \\\n",
       "0       13.71       14.02          14.07          14.30              10.17   \n",
       "1       14.64       14.58          14.81          14.62              10.70   \n",
       "2       14.41       14.38          14.51          14.62              10.49   \n",
       "3       14.76       14.93          14.99          15.30              10.83   \n",
       "4       15.08       15.02          15.19          15.43              10.98   \n",
       "\n",
       "   Monday_Adj Close   Friday_Volume  Monday_Volume  y  \n",
       "0              10.34         202700         306200  0  \n",
       "1              10.57         201000         361700  0  \n",
       "2              10.57         185900         229200  0  \n",
       "3              11.06         119500         148000  0  \n",
       "4              11.15         194300         239400  0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AHH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "AHH.to_csv('data/AHH.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCI: Bairings Corporate Investors, Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCI=pd.read_csv('data/MCI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stock.loc[:, stock.columns != 'Date'] = stock.loc[:, stock.columns != 'Date'].applymap(\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  stock['datetime'] = pd.to_datetime(stock['Date'], errors='coerce')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_stock['DayType'] = np.where(filtered_stock['datetime'].dt.dayofweek == 0, 'Monday', 'Friday')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:76: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  stock['y'] = stock['Friday_date'].isin(dst_fri_dates).astype(int)\n"
     ]
    }
   ],
   "source": [
    "MCI=cleaner(MCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCI.to_csv('data/MCI.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALOT: Astronova, Inc., Technology (computer peripheral equipment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALOT=pd.read_csv('data/ALOT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stock.loc[:, stock.columns != 'Date'] = stock.loc[:, stock.columns != 'Date'].applymap(\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  stock['datetime'] = pd.to_datetime(stock['Date'], errors='coerce')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_stock['DayType'] = np.where(filtered_stock['datetime'].dt.dayofweek == 0, 'Monday', 'Friday')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:76: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  stock['y'] = stock['Friday_date'].isin(dst_fri_dates).astype(int)\n"
     ]
    }
   ],
   "source": [
    "ALOT=cleaner(ALOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALOT.to_csv('data/ALOT.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMKR: Emcore Corporation, Technology (semiconductors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMKR=pd.read_csv('data/EMKR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stock.loc[:, stock.columns != 'Date'] = stock.loc[:, stock.columns != 'Date'].applymap(\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  stock['datetime'] = pd.to_datetime(stock['Date'], errors='coerce')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_stock['DayType'] = np.where(filtered_stock['datetime'].dt.dayofweek == 0, 'Monday', 'Friday')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:76: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  stock['y'] = stock['Friday_date'].isin(dst_fri_dates).astype(int)\n"
     ]
    }
   ],
   "source": [
    "EMKR=cleaner(EMKR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMKR.to_csv('data/EMKR.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HHC: Howard Hughes Corporation, Consumer Services (real estate investment trusts)\n",
    "\n",
    "They seem to have changed their name to Howard Hughes Holdings and the ticker is now HHH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHC=pd.read_csv('data/HHC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stock.loc[:, stock.columns != 'Date'] = stock.loc[:, stock.columns != 'Date'].applymap(\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  stock['datetime'] = pd.to_datetime(stock['Date'], errors='coerce')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_stock['DayType'] = np.where(filtered_stock['datetime'].dt.dayofweek == 0, 'Monday', 'Friday')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:76: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  stock['y'] = stock['Friday_date'].isin(dst_fri_dates).astype(int)\n"
     ]
    }
   ],
   "source": [
    "HHC=cleaner(HHC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHC.to_csv('data/HHC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSC: Norfolk Souther Corp, Transportation (railroads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSC=pd.read_csv('data/NSC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stock.loc[:, stock.columns != 'Date'] = stock.loc[:, stock.columns != 'Date'].applymap(\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  stock['datetime'] = pd.to_datetime(stock['Date'], errors='coerce')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_stock['DayType'] = np.where(filtered_stock['datetime'].dt.dayofweek == 0, 'Monday', 'Friday')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:76: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  stock['y'] = stock['Friday_date'].isin(dst_fri_dates).astype(int)\n"
     ]
    }
   ],
   "source": [
    "NSC = cleaner(NSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSC.to_csv('data/NSC.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTL: Unitil Corp., Public Utilities (power generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTL=pd.read_csv('data/UTL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:6: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  stock.loc[:, stock.columns != 'Date'] = stock.loc[:, stock.columns != 'Date'].applymap(\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  stock['datetime'] = pd.to_datetime(stock['Date'], errors='coerce')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_stock['DayType'] = np.where(filtered_stock['datetime'].dt.dayofweek == 0, 'Monday', 'Friday')\n",
      "/var/folders/4l/xdk1tfxx7jbd3zsydcl3t4vh0000gn/T/ipykernel_72220/3800731327.py:76: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  stock['y'] = stock['Friday_date'].isin(dst_fri_dates).astype(int)\n"
     ]
    }
   ],
   "source": [
    "UTL=cleaner(UTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "UTL.to_csv('data/UTL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
